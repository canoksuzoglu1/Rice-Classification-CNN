{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a871845",
   "metadata": {},
   "source": [
    "## 1. Libraries and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for building, training, and visualizing the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting constants for image processing and model training\n",
    "IMAGE_SIZE = 250  # The size to which all images will be resized\n",
    "BATCH_SIZE = 32   # Number of images per batch during training\n",
    "CHANNELS = 3      # Number of color channels (RGB)\n",
    "EPOCHS = 50       # Number of epochs to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf0ef5",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eaecb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the image dataset from a directory, shuffling, and setting image size and batch size\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Data\",\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Extracting class names from the dataset (corresponding to folder names)\n",
    "class_names = dataset.class_names\n",
    "\n",
    "# Function to sample a fraction of the dataset (for example, 1/15th of the full dataset)\n",
    "def sample_dataset(ds, fraction=1/15):\n",
    "    ds_size = tf.data.experimental.cardinality(ds).numpy()  # Getting the size of the dataset\n",
    "    sampled_size = int(ds_size * fraction)  # Calculating the sampled size\n",
    "    ds = ds.take(sampled_size)  # Taking a subset of the dataset\n",
    "    return ds\n",
    "\n",
    "# Reducing the dataset to a fraction for faster experimentation\n",
    "dataset = sample_dataset(dataset)\n",
    "len(dataset)  # Check the number of batches in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d43db",
   "metadata": {},
   "source": [
    "## 3. Image Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef78bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a few example images from the dataset with their corresponding labels\n",
    "plt.figure(figsize=(10,10))\n",
    "for image_batch, image_label in dataset.take(1):  # Taking one batch (shuffled) from the dataset\n",
    "    for i in range(12):  # Displaying 12 images\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))  # Show image\n",
    "        plt.title(class_names[image_label[i]])  # Display class name as title\n",
    "        plt.axis(\"off\")  # Turn off axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3de96a",
   "metadata": {},
   "source": [
    "## 4. Dataset Splitting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da35159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset into training, validation, and test sets\n",
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "    ds_size = len(ds)  # Total size of the dataset\n",
    "    \n",
    "    # Shuffle the dataset if required\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    # Calculate the sizes of each subset\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    # Create the train, validation, and test datasets\n",
    "    train_ds = ds.take(train_size)  # Take the first portion for training\n",
    "    val_ds = ds.skip(train_size).take(val_size)  # Skip the training set and take validation set\n",
    "    test_ds = ds.skip(train_size).skip(val_size)  # Skip training and validation, take the rest as test set\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation, and test sets\n",
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the sizes of the train, validation, and test datasets\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c68c1",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving data pipeline performance by caching and prefetching batches\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a568ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing layers for resizing and rescaling images\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),  # Resizing images to the specified size\n",
    "    layers.Rescaling(1.0/256)  # Normalizing pixel values between 0 and 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation layers to randomly flip and rotate images during training\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip images horizontally and vertically\n",
    "    layers.RandomRotation(0.2)  # Randomly rotate images by 20% to improve generalization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c18fb",
   "metadata": {},
   "source": [
    "## 6. Model Definition and Customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input shape of the model and number of output classes\n",
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 5  # Assuming there are 5 classes\n",
    "\n",
    "# Building a simple convolutional neural network (CNN) model\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,  # Apply resizing and rescaling to input images\n",
    "    data_augmentation,  # Apply data augmentation during training\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),  # First convolutional layer\n",
    "    layers.MaxPool2D((2, 2)),  # Max pooling layer to reduce spatial dimensions\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),  # Second convolutional layer\n",
    "    layers.MaxPool2D((2, 2)),  # Max pooling layer\n",
    "    layers.Flatten(),  # Flatten the output for the fully connected layer\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer with 128 units\n",
    "    layers.Dense(n_classes, activation='softmax')  # Output layer with softmax activation for classification\n",
    "])\n",
    "\n",
    "# Building the model with the specified input shape\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the model summary (layer details)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53724fc0",
   "metadata": {},
   "source": [
    "## 7. Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36978da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Defining the optimizer with a small learning rate\n",
    "optimizer = Adam(learning_rate=1e-5)  # Reducing learning rate for better convergence\n",
    "\n",
    "# Compiling the model with an appropriate loss function and evaluation metric\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),  # Loss for multi-class classification\n",
    "    metrics=['accuracy']  # Evaluate model performance using accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd84107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a callback to save the best model based on validation loss\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_checkpoint.keras',\n",
    "    save_best_only=True,  # Save only the model with the lowest validation loss\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    mode='min'  # Save the model when the validation loss is minimized\n",
    ")\n",
    "\n",
    "# Training the model on the training data, validating on the validation data\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,  # Display progress during training\n",
    "    validation_data=val_ds,  # Use the validation data to monitor performance\n",
    "    callbacks=[checkpoint_callback]  # Use the checkpoint callback to save the best model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test dataset\n",
    "score = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813d452",
   "metadata": {},
   "source": [
    "## 8. Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model to a specified directory\n",
    "model_version = 1\n",
    "save_dir = f\"./models/{model_version}.keras\"\n",
    "\n",
    "# Checking if the directory exists and creating it if necessary\n",
    "os.makedirs(os.path.dirname(save_dir), exist_ok=True)\n",
    "\n",
    "# Saving the model to the specified directory\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model for future use\n",
    "model_version = 1\n",
    "model_path = f\"./models/{model_version}.keras\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bbd3e8",
   "metadata": {},
   "source": [
    "## 9. Prediction Function and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions on a single image and return the predicted class and confidence\n",
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)  # Convert image to array\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Add a batch dimension\n",
    "    \n",
    "    predictions = model.predict(img_array)  # Make predictions\n",
    "    \n",
    "    # Get the predicted class and confidence\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]  # Class with the highest probability\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)  # Confidence score in percentage\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing predictions on the test dataset\n",
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):  # Taking one batch from the test set\n",
    "    for i in range(9):  # Display 9 images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))  # Show the image\n",
    "        \n",
    "        # Get predicted and actual class labels with confidence scores\n",
    "        predicted_class, confidence = predict(model, images[i])\n",
    "        actual_class = class_names[labels[i]]\n",
    "        \n",
    "        # Display the predicted and actual class labels\n",
    "        plt.title(f\"Predicted: {predicted_class} ({confidence}%)\\nActual: {actual_class}\")\n",
    "        plt.axis('off')  # Turn off axis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

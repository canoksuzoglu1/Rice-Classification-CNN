{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 250\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eaecb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Data\",\n",
    "    shuffle=True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names\n",
    "\n",
    "def sample_dataset(ds, fraction=1/15):\n",
    "    ds_size = tf.data.experimental.cardinality(ds).numpy()\n",
    "    sampled_size = int(ds_size * fraction)\n",
    "    ds = ds.take(sampled_size)\n",
    "    return ds\n",
    "\n",
    "dataset = sample_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99392373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset) # Batch quantity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef78bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "#for image_batch, image_label in dataset.take(1):  # Take 1 batch and in shuffle mode(Everytime is diffrent)\n",
    "    #for i in range(12):\n",
    "       # ax = plt.subplot(3,4, i+1)\n",
    "       # plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "       # plt.title(class_names[image_label[i]])\n",
    "       # plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da35159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for split dataset\n",
    "\n",
    "## In tensorflow there is no ready-func for split so we create one\n",
    "\n",
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n",
    "    \n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed = 12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling our func for split\n",
    "\n",
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a568ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and rescale\n",
    "\n",
    "resize_and_rescale=tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE), # Make sure everything in the same size\n",
    "    layers.Rescaling(1.0/256) # Make every channel rate between 0 and 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 5\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),  # Daha küçük bir model\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36978da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Öğrenme oranını azaltarak optimizörü yeniden tanımlayalım\n",
    "optimizer = Adam(learning_rate=1e-5)  # Öğrenme oranını daha küçük bir değere çekiyoruz\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd84107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_checkpoint.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    \n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be987c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i])\n",
    "        actual_class = class_names[labels[i]]\n",
    "        \n",
    "        plt.title(f\"Predicted: {predicted_class} ({confidence}%)\\nActual: {actual_class}\")\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model versiyonu\n",
    "model_version = 1\n",
    "save_dir = f\"./models/{model_version}.keras\"\n",
    "\n",
    "# Klasörün var olup olmadığını kontrol et ve gerekirse oluştur\n",
    "os.makedirs(os.path.dirname(save_dir), exist_ok=True)\n",
    "\n",
    "# Modeli kaydet\n",
    "model.save(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_version = 1\n",
    "model_path = f\"./models/{model_version}.keras\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
